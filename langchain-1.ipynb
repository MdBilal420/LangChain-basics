{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c95df1-0d86-43a1-ace5-c2788f4e4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-openai) (0.1.52)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-openai) (1.28.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.57)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.5.10)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55dcae66-7cae-44e2-8e82-e281cd234209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d72332-565e-4c64-aa3d-1a32ba94a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c5cafa-01d7-4954-8743-835fc8d8df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91583128-e8fd-4a93-824d-7920e2e3b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2528ef7-183b-4cb7-a545-e2395d575014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1e1961-30a0-49fe-b3a0-4936e02f8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_creative_llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d674021-c873-4937-9f30-b7bb7f7de3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the 5 best things about generative ai?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37dbc43d-b658-47a4-9716-e0e1d9954d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohdb\\gen-ai\\langchain-1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Unlimited Creativity: Generative AI has the ability to generate unique and original content, designs, and ideas that may not have been possible otherwise. The algorithms used in generative AI are constantly evolving and can create endless variations, making it a valuable tool for artists and designers looking for new inspiration.\n",
      "\n",
      "2. Efficiency and Speed: Generative AI can produce large amounts of content in a short period of time, making it a highly efficient tool for industries such as advertising, marketing, and content creation. This saves time and resources while still maintaining high levels of quality.\n",
      "\n",
      "3. Personalization: With Generative AI, content can be personalized for specific individuals or groups, making it more relevant and engaging. This allows businesses to create tailor-made experiences for their customers, leading to better engagement and increased customer satisfaction.\n",
      "\n",
      "4. Automated Training and Learning: Generative AI is capable of learning and improving on its own without the need for human intervention. This means that the AI can become more efficient and accurate over time, leading to better results and enhanced user experience.\n",
      "\n",
      "5. Applications in Various Industries: Generative AI has a wide range of applications in different industries such as art, design, music, marketing, and healthcare. Its versatility and adaptability make it a valuable tool for businesses\n"
     ]
    }
   ],
   "source": [
    "print(my_creative_llm(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c99aac-d3ee-4316-8683-4efab3b09b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_creative_llm = OpenAI(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2e8101-40df-406e-92a0-819987ca6d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65be5837-1b50-40d0-a60c-3e0f1c90d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What are the 3 best things about football?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176f93c6-15dc-4dd0-803d-649bf9053684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Teamwork and camaraderie: Football is a team sport and requires players to work together towards a common goal. This fosters a sense of camaraderie and creates strong bonds between teammates.\n",
      "\n",
      "2. Physical fitness and athleticism: Football is a physically demanding sport that requires players to be in top physical shape. It helps improve overall fitness, strength, and agility.\n",
      "\n",
      "3. Strategic and tactical thinking: Football is not just about physical prowess, it also requires strategic and tactical thinking. Players must constantly analyze and adjust their game plan to outsmart their opponents. This makes football an intellectually stimulating sport.\n"
     ]
    }
   ],
   "source": [
    "print(my_creative_llm(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c701786f-54eb-45f6-a327-6e760f5f3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 11.1 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "     -------------------------------------- 370.8/370.8 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (0.1.57)\n",
      "Collecting numpy<2,>=1\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.7/76.7 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.3/49.3 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "     -------------------------------------- 292.8/292.8 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohdb\\gen-ai\\langchain-1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, yarl, typing-inspect, SQLAlchemy, aiosignal, dataclasses-json, aiohttp, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 dataclasses-json-0.6.6 frozenlist-1.4.1 greenlet-3.0.3 langchain-0.1.20 langchain-community-0.0.38 langchain-text-splitters-0.0.1 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26213ed3-db1a-4311-8f82-68c146177675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "312d2232-9a92-43e3-8ad0-e70af0279d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt_template = PromptTemplate(\n",
    "    input_variables = [\"destination\"],\n",
    "    template = \"What are the 3 best things to do in {destination}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eabdf9b-3d97-44a5-b2cd-7a0913fe7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"madrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b41820c-7217-4678-8559-b330b0b683bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Visit the Prado Museum: The Prado Museum is one of the most famous and largest art museums in the world, housing a vast collection of Spanish and European art from the 12th to the 19th century. It is a must-visit for art lovers and history buffs.\n",
      "\n",
      "2. Stroll through the Retiro Park: Retiro Park is a beautiful and peaceful green oasis in the heart of Madrid. It is the perfect place to relax, have a picnic, or rent a boat and row on the lake. The park also has several interesting landmarks, such as the Crystal Palace and the Fallen Angel statue.\n",
      "\n",
      "3. Try traditional Spanish food: Madrid is known for its delicious food, and trying traditional Spanish dishes is a must-do when visiting the city. From tapas to paella, there are endless options to choose from. Make sure to also try the famous churros con chocolate for a sweet treat.\n"
     ]
    }
   ],
   "source": [
    "print(my_creative_llm(my_prompt_template.format(destination=user_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d6df973-9e8e-457d-817e-9ced49f50d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b2f983f-11a8-43ab-a9d5-06d67e95cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt_template = PromptTemplate(\n",
    "    input_variables = [\"athlete\"],\n",
    "    template = \"What are the 3 most remarkable achievements of {athlete}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d748992-fbfa-4f76-a1cc-3d525583b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_no_creative_llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38aed997-9d63-4e90-815b-95366129e35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohdb\\gen-ai\\langchain-1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "my_chain = LLMChain(llm=my_no_creative_llm, prompt=my_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "754a52b3-55b7-4f44-819b-4d3bb71132ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohdb\\gen-ai\\langchain-1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Record-Breaking Goal Scoring: Messi has broken numerous goal-scoring records throughout his career, including becoming the all-time top scorer for both FC Barcelona and La Liga. He has also won the European Golden Shoe award for the highest goal scorer in Europe six times, the most by any player.\n",
      "\n",
      "2. Multiple Ballon d'Or Awards: Messi has won the prestigious Ballon d'Or award six times, the most by any player in history. This award is given to the best player in the world, and Messi's consistent performances and achievements have earned him this honor multiple times.\n",
      "\n",
      "3. Champions League Success: Messi has played a crucial role in FC Barcelona's success in the UEFA Champions League, winning the competition four times. He has also been the top scorer in the Champions League six times, further solidifying his status as one of the greatest players in the competition's history.\n"
     ]
    }
   ],
   "source": [
    "print(my_chain.run(\"messi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "532f8fcc-23b3-4167-9bbc-a9b9092acc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf6b3bf7-7de5-4d89-b12b-25c0e25d7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_no_creative_llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd1583cc-6bf0-4ec5-bc13-38a87aedb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conversation = ConversationChain(llm=my_no_creative_llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f7172d-73b2-4b48-aca8-63dfe3d49ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohdb\\gen-ai\\langchain-1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hi friend!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi friend!',\n",
       " 'history': '',\n",
       " 'response': \" Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation(\"hi friend!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e7f6060-986b-4d6a-bc4b-964b5beed55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi friend!\n",
      "AI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\n",
      "Human: I am from india. where are you from?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I am from india. where are you from?',\n",
       " 'history': \"Human: hi friend!\\nAI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\",\n",
       " 'response': ' I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation(\"I am from india. where are you from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b4204ee-3422-47c0-88f5-3681d54b8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi friend!\n",
      "AI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\n",
      "Human: I am from india. where are you from?\n",
      "AI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\n",
      "Human: Do you remember where i am from?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation.predict(input=\"Do you remember where i am from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f91ec023-23d2-4c8d-a7de-76acaa079dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi friend!\n",
      "AI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\n",
      "Human: I am from india. where are you from?\n",
      "AI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\n",
      "Human: Do you remember where i am from?\n",
      "AI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\n",
      "Human: i just told you, did you forgot?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'i just told you, did you forgot?',\n",
       " 'history': \"Human: hi friend!\\nAI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\\nHuman: I am from india. where are you from?\\nAI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\\nHuman: Do you remember where i am from?\\nAI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\",\n",
       " 'response': ' I apologize, I misunderstood your previous question. As an AI, I do not have the ability to forget information. I am constantly learning and updating my knowledge base. Can you please remind me of your location?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation(\"i just told you, did you forgot?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f64f08e7-ae1b-4e0f-803d-c24c5dcb9759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi friend!\n",
      "AI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\n",
      "Human: I am from india. where are you from?\n",
      "AI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\n",
      "Human: Do you remember where i am from?\n",
      "AI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\n",
      "Human: i just told you, did you forgot?\n",
      "AI:  I apologize, I misunderstood your previous question. As an AI, I do not have the ability to forget information. I am constantly learning and updating my knowledge base. Can you please remind me of your location?\n",
      "Human: india\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'india',\n",
       " 'history': \"Human: hi friend!\\nAI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\\nHuman: I am from india. where are you from?\\nAI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\\nHuman: Do you remember where i am from?\\nAI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\\nHuman: i just told you, did you forgot?\\nAI:  I apologize, I misunderstood your previous question. As an AI, I do not have the ability to forget information. I am constantly learning and updating my knowledge base. Can you please remind me of your location?\",\n",
       " 'response': ' Thank you for reminding me. As I mentioned before, I have access to information about India. Is there something specific you would like to know about your country?'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef63778b-72de-4fa1-93e1-850bc876066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi friend!\n",
      "AI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\n",
      "Human: I am from india. where are you from?\n",
      "AI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\n",
      "Human: Do you remember where i am from?\n",
      "AI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\n",
      "Human: i just told you, did you forgot?\n",
      "AI:  I apologize, I misunderstood your previous question. As an AI, I do not have the ability to forget information. I am constantly learning and updating my knowledge base. Can you please remind me of your location?\n",
      "Human: india\n",
      "AI:  Thank you for reminding me. As I mentioned before, I have access to information about India. Is there something specific you would like to know about your country?\n",
      "Human: do you know, where i am from ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'do you know, where i am from ?',\n",
       " 'history': \"Human: hi friend!\\nAI:  Hello there! It's nice to meet you. I am an AI created by OpenAI, a research organization focused on artificial intelligence. I am constantly learning and improving my abilities through data and algorithms. How can I assist you today?\\nHuman: I am from india. where are you from?\\nAI:  I am not physically located anywhere as I am a digital entity. However, my creators are based in San Francisco, California. I have access to information from all over the world, including India. Is there something specific you would like to know about India?\\nHuman: Do you remember where i am from?\\nAI:  I do not have the ability to remember specific information about individuals. However, I can access information about your location if you have shared it with me. Would you like me to search for your location in my database?\\nHuman: i just told you, did you forgot?\\nAI:  I apologize, I misunderstood your previous question. As an AI, I do not have the ability to forget information. I am constantly learning and updating my knowledge base. Can you please remind me of your location?\\nHuman: india\\nAI:  Thank you for reminding me. As I mentioned before, I have access to information about India. Is there something specific you would like to know about your country?\",\n",
       " 'response': ' As I mentioned before, I do not have the ability to remember specific information about individuals. However, based on our previous conversation, I can infer that you are from India. Is there something specific you would like to know about your country?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conversation(\"do you know, where i am from ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198a95f-9b12-4350-beb0-2bc6e178faae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
